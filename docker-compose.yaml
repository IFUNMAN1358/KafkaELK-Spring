version: '3.8'
services:

  elasticsearch:
    container_name: elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELK_VERSION}
    volumes:
      - ./docker_configs/elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro
      - ./docker_volumes/elasticsearch:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      ES_JAVA_OPTS: "-Xmx512m -Xms512m"
      ELASTIC_USERNAME: ${ELASTIC_USERNAME}
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD}
    networks:
      - elk
    restart: unless-stopped

  logstash:
    container_name: logstash
    image: docker.elastic.co/logstash/logstash:${ELK_VERSION}
    volumes:
      - ./docker_configs/logstash/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./docker_configs/logstash/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro
      - ./docker_configs/logstash/clients:/usr/share/logstash/clients
    ports:
      - "5044:5044"
      - "5000:5000"
      - "9600:9600"
    environment:
      LS_JAVA_OPTS: -Xms256m -Xmx256m
      ELASTIC_USERNAME: ${ELASTIC_USERNAME}
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD}
      LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD}
    networks:
      - elk
      - kafka-logstash
    depends_on:
      - elasticsearch
    restart: unless-stopped

  kibana:
    container_name: kibana
    image: docker.elastic.co/kibana/kibana:${ELK_VERSION}
    volumes:
      - ./docker_configs/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml:ro
    ports:
      - "5601:5601"
    environment:
      KIBANA_SYSTEM_USERNAME: ${KIBANA_SYSTEM_USERNAME}
      KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD}
    networks:
      - elk
    depends_on:
      - elasticsearch
    restart: unless-stopped

  zookeeper2:
    container_name: zookeeper2
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_SERVERS: zookeeper2:2888:3888
    hostname: zookeeper2
    ports:
      - "2181:2181"
    networks:
      - kafka

  kafka2:
    container_name: kafka2
    image: confluentinc/cp-kafka:latest
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka2:19092,EXTERNAL://kafka2:9092,DOCKER://host.docker.internal:29092
      # INTERNAL - for containers in one docker network
      # EXTERNAL - for client outside the docker network and host
      # DOCKER - for client outside the docker network, but in one host
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper2:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_JMX_PORT: 9999
      KAFKA_JMX_HOSTNAME: ${DOCKER_HOST_IP:-127.0.0.1}
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
    hostname: kafka2
    ports:
      - "9092:9092"
      - "29092:29092"
      - "9999:9999"
    depends_on:
      - zookeeper2
    networks:
      - kafka
      - kafka-logstash

networks:
  elk:
    driver: bridge
  kafka:
    driver: bridge
  kafka-logstash:
    driver: bridge